{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "\n",
    "# Load model and labels\n",
    "model = joblib.load('mlp_tsl_static.pkl')\n",
    "le = LabelEncoder()\n",
    "le.fit([chr(i) for i in range(ord('A'), ord('Z') + 1)])\n",
    "\n",
    "# MediaPipe setup\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                       min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "\n",
    "# Normalize landmarks\n",
    "def normalize_landmarks(landmarks):\n",
    "    coords = np.array(landmarks).reshape(-1, 3).astype(np.float32)\n",
    "    coords_min = coords.min(axis=0)\n",
    "    coords_max = coords.max(axis=0)\n",
    "    norm_coords = (coords - coords_min) / (coords_max - coords_min + 1e-6)\n",
    "    return norm_coords.flatten().reshape(1, -1)\n",
    "\n",
    "# Save to file\n",
    "def save_output_to_file(text):\n",
    "    os.makedirs('sound', exist_ok=True)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    path = f'sound/output_{timestamp}.txt'\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "# Main app\n",
    "class TSLApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"TSL - Bridging Silence\")\n",
    "        self.root.configure(bg=\"#f0f4f8\")\n",
    "\n",
    "        self.video_running = False\n",
    "        self.cap = None\n",
    "\n",
    "        self.prev_letter = \"\"\n",
    "        self.letter_hold_start = None\n",
    "        self.last_seen_time = time.time()\n",
    "        self.word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.saved_sentences = []\n",
    "\n",
    "        # UI\n",
    "        self.video_label = tk.Label(root, bg=\"#e6ecf0\")\n",
    "        self.video_label.pack(padx=10, pady=10)\n",
    "\n",
    "        self.prediction_label = tk.Label(root, text=\"Letter: \", font=(\"Arial\", 18), fg=\"#007acc\", bg=\"#f0f4f8\")\n",
    "        self.prediction_label.pack()\n",
    "\n",
    "        self.controls = tk.Frame(root, bg=\"#f0f4f8\")\n",
    "        self.controls.pack(pady=10)\n",
    "\n",
    "        tk.Button(self.controls, text=\"Start\", command=self.start_video,\n",
    "                  bg=\"#28a745\", fg=\"white\", font=(\"Arial\", 12)).grid(row=0, column=0, padx=5)\n",
    "        tk.Button(self.controls, text=\"Stop\", command=self.stop_video,\n",
    "                  bg=\"#dc3545\", fg=\"white\", font=(\"Arial\", 12)).grid(row=0, column=1, padx=5)\n",
    "        tk.Button(self.controls, text=\"Clear\", command=self.clear_predictions,\n",
    "                  bg=\"#ffc107\", font=(\"Arial\", 12)).grid(row=0, column=2, padx=5)\n",
    "        tk.Button(self.controls, text=\"Speak\", command=self.speak_text,\n",
    "                  bg=\"#17a2b8\", fg=\"white\", font=(\"Arial\", 12)).grid(row=0, column=3, padx=5)\n",
    "\n",
    "    def start_video(self):\n",
    "        if not self.video_running:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            self.video_running = True\n",
    "            self.update_video()\n",
    "\n",
    "    def stop_video(self):\n",
    "        self.video_running = False\n",
    "        if self.cap:\n",
    "            self.cap.release()\n",
    "        self.video_label.config(image='')\n",
    "\n",
    "    def clear_predictions(self):\n",
    "        self.word = \"\"\n",
    "        self.sentence = \"\"\n",
    "        self.saved_sentences.clear()\n",
    "        self.prediction_label.config(text=\"Letter: \")\n",
    "\n",
    "    def speak_text(self):\n",
    "        # Disabled pyttsx3: only save to file and clear text\n",
    "        full_sentence = (self.sentence + self.word).strip()\n",
    "        if full_sentence:\n",
    "            save_output_to_file(full_sentence)\n",
    "            self.saved_sentences.append(full_sentence)\n",
    "            self.word = \"\"\n",
    "            self.sentence = \"\"\n",
    "            self.prediction_label.config(text=\"Letter: \")\n",
    "\n",
    "    def update_video(self):\n",
    "        if not self.video_running:\n",
    "            return\n",
    "\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.stop_video()\n",
    "            return\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(rgb)\n",
    "\n",
    "        current_time = time.time()\n",
    "        hand_detected = False\n",
    "        current_letter = \"\"\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_detected = True\n",
    "            self.last_seen_time = current_time\n",
    "\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                landmarks = [(lm.x, lm.y, lm.z) for lm in hand_landmarks.landmark]\n",
    "\n",
    "                try:\n",
    "                    X = normalize_landmarks(landmarks)\n",
    "                    pred_index = model.predict(X)[0]\n",
    "                    current_letter = le.inverse_transform([pred_index])[0]\n",
    "\n",
    "                    if current_letter == self.prev_letter:\n",
    "                        if not self.letter_hold_start:\n",
    "                            self.letter_hold_start = current_time\n",
    "                        if current_time - self.letter_hold_start >= 1:\n",
    "                            if not self.word or self.word[-1] != current_letter:\n",
    "                                self.word += current_letter\n",
    "                    else:\n",
    "                        self.letter_hold_start = current_time\n",
    "\n",
    "                    self.prev_letter = current_letter\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(\"Prediction error:\", e)\n",
    "\n",
    "        else:\n",
    "            # No hand detected\n",
    "            time_since_last = current_time - self.last_seen_time\n",
    "            if time_since_last >= 2 and self.word and (not self.word.endswith(\" \")):\n",
    "                self.word += \" \"\n",
    "            if time_since_last >= 5 and self.word.strip():\n",
    "                self.sentence += self.word.strip() + \" \"\n",
    "                self.word = \"\"\n",
    "\n",
    "        display_text = f\"Letter: {current_letter}\\nWord: {self.word}\\nSentence: {self.sentence}\"\n",
    "        self.prediction_label.config(text=display_text)\n",
    "\n",
    "        img = Image.fromarray(rgb)\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        self.video_label.imgtk = imgtk\n",
    "        self.video_label.configure(image=imgtk)\n",
    "\n",
    "        self.root.after(10, self.update_video)\n",
    "\n",
    "# Run app\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = TSLApp(root)\n",
    "    root.mainloop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cfdfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\alphabet model production\\alphabetmodel_production\\.conda\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement 2.0.2 (from versions: none)\n",
      "ERROR: No matching distribution found for 2.0.2\n"
     ]
    }
   ],
   "source": [
    "%pip  install  numpy 2.0.2 mediapipe joblib scikit-learn opencv-python Pillow\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
